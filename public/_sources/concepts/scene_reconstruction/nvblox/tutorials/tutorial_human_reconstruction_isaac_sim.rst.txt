Human Reconstruction in Isaac Sim
==================================

.. figure:: :ir_lfs:`<resources/isaac_ros_docs/repositories_and_packages/isaac_ros_nvblox/isaac_sim_nvblox_humans.gif>`
   :align: center
   :width: 600px

In this tutorial we'll demonstrate how one can perform human
reconstruction in nvblox with Isaac Sim. The detected humans are then
visible in a separate dynamic costmap that can be used for navigation
with `Nav2 <https://github.com/ros-planning/navigation2>`__. If you want to know how human reconstruction works behind the
scenes refer to the :doc:`/concepts/scene_reconstruction/nvblox/technical_details`.

.. note::

   Due to a known issue, the animation of humans in the scene will not happen.

Tutorial Walkthrough
--------------------

In this part, we demonstrate how to use Isaac Sim for human
reconstruction in nvblox. We use the ground truth semantic segmentation
coming from the simulation as input to detect humans. This demonstration
relies on the extensions
`omni.anim.people <https://docs.omniverse.nvidia.com/isaacsim/latest/features/warehouse_logistics/ext_omni_anim_people.html>`__
and
`omni.anim.navigation <https://docs.omniverse.nvidia.com/extensions/latest/ext_navigation-mesh.html>`__
to make humans navigate in the environment while the robot is moving.

Running the demonstration scene
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Before continuing this tutorial, make sure that the
:doc:`tutorial_isaac_sim` is working fine.

1. Open the Isaac Sim terminal and export the needed environment variables 
   as explained in steps 2-3 of the :doc:`Isaac Sim Setup Guide </getting_started/isaac_sim/index>`.

2. Start the simulation by running the below command in the terminal opened in the previous step:

   .. code:: bash

      ./python.sh ~/workspaces/isaac_ros-dev/src/isaac_ros_nvblox/nvblox_examples/nvblox_isaac_sim/omniverse_scripts/start_isaac_sim.py --with_people --gpu_physics_enabled --scenario_path=/Isaac/Samples/NvBlox/carter_warehouse_navigation_with_people.usd

   .. note::

      The ``start_isaac_sim`` script is explained in detail
      :ir_repo:`here <isaac_ros_nvblox> <nvblox_examples/nvblox_isaac_sim/omniverse_scripts/README.md>`.
   .. note::

      Because the animation requires to execute Python
      scripts, running the scene with the UI will pop a window up asking
      to confirm that you want to enable script execution. Click Yes to
      make it possible to start the scene and the human animation.

3. *In another terminal* run the ROS Docker container using the ``run_dev.sh`` script:

   .. code:: bash

      cd ~/workspaces/isaac_ros-dev/src/isaac_ros_common && \
        ./scripts/run_dev.sh

4.  Inside the container, build and source the workspace:

    .. code:: bash

       cd /workspaces/isaac_ros-dev && \
         colcon build --symlink-install && \
         source install/setup.bash

5. Launch nvblox configured for human mapping:

   .. code:: bash

      ros2 launch nvblox_examples_bringup isaac_sim_humans_example.launch.py


Running with custom human paths
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The above section launches the default human paths. If you want to have other paths
taken by the humans, you can either:

-  Change the default human animation file manually directly on the
   server
-  Use the randomization options of the above script. To do so:

   .. code:: bash

        ./python.sh ~/workspaces/isaac_ros-dev/src/isaac_ros_nvblox/nvblox_examples/nvblox_isaac_sim/omniverse_scripts/start_isaac_sim.py \
          --with_people --scenario_path=/Isaac/Samples/NvBlox/carter_warehouse_navigation_with_people.usd \
          --gpu_physics_enabled --anim_people_waypoint_dir <path_to_folder> --with_people --random_command_generation

   This will launch the scene headless (without visualization) and
   generate a new ``human_cmd_file.txt`` in ``<path_to_folder>``. By
   default, it will generate 5 waypoints per human, but it is possible
   to change this with the option
   ``--num_waypoints=<number_of_waypoints>``. Then you can either
   manually upload the script file to replace the default one, or use
   the same command as step 2. by adding
   ``--use_generated_command_file --anim_people_waypoint_dir <path_to_folder>``
   to automatically set the script file.


Running on a custom scene
^^^^^^^^^^^^^^^^^^^^^^^^^

If you want to test the reconstruction on another scene:

-  Complete the `Running the demonstration scene`_ section.

-  Make sure you use the same robot USD so that the topic names and Isaac Sim ROS
   bridge is correctly set up.

-  Make sure that humans you add to the scene have the ``person``
   semantic segmentation class. To do so, you can use the Semantics
   Schema Editor on the top prim of the additional humans.

-  Make sure that all humans are under */World/Humans* for them to be
   picked up by the randomization.

Troubleshooting
---------------

Refer to the
:doc:`/repositories_and_packages/isaac_ros_nvblox/isaac_ros_nvblox/troubleshooting/troubleshooting_nvblox_isaac_sim`.
