==============
|package_name|
==============

Quickstart
----------

1.  Complete steps 1-5 of the quickstart
    `here <../README.md#quickstart>`__
2.  Select a CenterPose model by visiting the CenterPose model
    collection available on the official `CenterPose
    GitHub <https://github.com/NVlabs/CenterPose>`__ repository
    `here <https://drive.google.com/drive/folders/1QIxcfKepOR4aktOz62p3Qag0Fhm0LVa0>`__.
    The model is assumed to be downloaded to ``~/Downloads`` outside the
    docker container. This example will use ``shoe_resnet_140.pth``,
    which should be downloaded into ``/tmp/models`` inside the docker
    container: >
.. note::

   this should be run outside the container

    .. code:: bash

       cd ~/Downloads && \
       docker cp shoe_resnet_140.pth isaac_ros_dev-x86_64-container:/tmp/models

    ..

    
.. warning::

   The models in the root directory of the model
       collection listed above will *NOT WORK* with our inference nodes
       because they have custom layers not supported by TensorRT nor
       Triton. Make sure to use the PyTorch weights that have the string
       ``resnet`` in their file names.

3.  Create a models repository with version ``1``:

    .. code:: bash

       mkdir -p /tmp/models/centerpose_shoe/1

4.  Create a configuration file for this model at path
    ``/tmp/models/centerpose_shoe/config.pbtxt``. Note that name has to
    be the same as the model repository name. Take a look at the example
    at ``isaac_ros_centerpose/test/models/centerpose_shoe/config.pbtxt``
    and copy that file to ``/tmp/models/centerpose_shoe/config.pbtxt``.

    .. code:: bash

       cp /workspaces/isaac_ros-dev/src/isaac_ros_pose_estimation/isaac_ros_centerpose/test/models/centerpose_shoe/config.pbtxt /tmp/models/centerpose_shoe/config.pbtxt

5.  To run the TensorRT engine plan, convert the PyTorch model to ONNX
    first. Export the model into an ONNX file using the script provided
    under
    ``/workspaces/isaac_ros-dev/src/isaac_ros_pose_estimation/isaac_ros_centerpose/scripts/centerpose_pytorch2onnx.py``:

    .. code:: bash

       python3 /workspaces/isaac_ros-dev/src/isaac_ros_pose_estimation/isaac_ros_centerpose/scripts/centerpose_pytorch2onnx.py --input /tmp/models/shoe_resnet_140.pth --output /tmp/models/centerpose_shoe/1/model.onnx

6.  To get a TensorRT engine plan file with Triton, export the ONNX
    model into an TensorRT engine plan file using the builtin TensorRT
    converter ``trtexec``:

    .. code:: bash

       /usr/src/tensorrt/bin/trtexec --onnx=/tmp/models/centerpose_shoe/1/model.onnx --saveEngine=/tmp/models/centerpose_shoe/1/model.plan

7.  Inside the container, build and source the workspace:

    .. code:: bash

       cd /workspaces/isaac_ros-dev && \
         colcon build --symlink-install && \
         source install/setup.bash

8.  Start ``isaac_ros_centerpose`` using the launch file:

    .. code:: bash

       ros2 launch isaac_ros_centerpose isaac_ros_centerpose.launch.py model_name:=centerpose_shoe model_repository_paths:=['/tmp/models']

    Then open **another** terminal, and enter the Docker container
    again:

    .. code:: bash

       cd ~/workspaces/isaac_ros-dev/src/isaac_ros_common && \
         ./scripts/run_dev.sh

    Then, play the ROS bag:

    .. code:: bash

       ros2 bag play -l src/isaac_ros_pose_estimation/resources/rosbags/centerpose_rosbag/

9.  Open another terminal window and attach to the same container. You
    should be able to get the poses of the objects in the images through
    ``ros2 topic echo``:

    In a **third** terminal, enter the Docker container again:

    .. code:: bash

       cd ~/workspaces/isaac_ros-dev/src/isaac_ros_common && \
         ./scripts/run_dev.sh

    .. code:: bash

       source install/setup.bash && \
         ros2 topic echo /object_poses

10. Launch ``rviz2``. Click on ``Add`` button, select “By topic”, and
    choose ``MarkerArray`` under ``/object_poses``. Set the fixed frame
    to ``centerpose``. You’ll be able to see the cuboid marker
    representing the object’s pose detected!

API
----

ROS Parameters
^^^^^^^^^^^^^^

======================= ============== ================================================================================================== ===================================================================================================================================================================================
ROS Parameter           Type           Default                                                                                            Description
======================= ============== ================================================================================================== ===================================================================================================================================================================================
``camera_matrix``       ``float list`` ``[616.078125, 0.0, 325.8349304199219, 0.0, 616.1030883789062, 244.4612274169922, 0.0, 0.0, 1.0]`` A row-major array of 9 floats that represent the camera intrinsics matrix ``K``.
``original_image_size`` ``float list`` ``[640, 480]``                                                                                     An array of two floats that represent the size of the original image passed into the image encoder. The first element needs to be width, and the second element needs to be height.
``output_field_size``   ``int list``   ``[128, 128]``                                                                                     An array of two integers that represent the size of the 2D keypoint decoding from the network output
``height``              ``float``      ``0.1``                                                                                            This parameter is used to scale the cuboid used for calculating the size of the objects detected.
``frame_id``            ``string``     ``centerpose``                                                                                     The frame ID that the DOPE decoder node will write to the header of its output messages
``marker_color``        ``float list`` ``[1.0, 0.0, 0.0, 1.0]`` (red)                                                                     An array of 4 floats representing RGBA that will be used to define the color that will be used by RViz to visualize the marker. Each value should be between 0.0 and 1.0.
======================= ============== ================================================================================================== ===================================================================================================================================================================================

Configuration File
^^^^^^^^^^^^^^^^^^

The default parameters for the ``CenterPoseDecoderNode`` is defined in the ``decoders_param.yaml`` file under ``isaac_ros_centerpose/config``. The ``decoders_param.yaml`` file uses the camera intrinsics of RealSense by default - if you are using a different camera, you will need to modify the ``camera_matrix`` field.


============== ==================================================================================================================================================================== ===================================================================
ROS Topic      Interface                                                                                                                                                            Description
============== ==================================================================================================================================================================== ===================================================================
``tensor_sub`` `isaac_ros_tensor_list_interfaces/TensorList <https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common/blob/main/isaac_ros_tensor_list_interfaces/msg/TensorList.msg>`__ The TensorList that contains the outputs of the CenterPose network.
============== ==================================================================================================================================================================== ===================================================================

ROS Topics Published
^^^^^^^^^^^^^^^^^^^^
ROS Topic        Interface                                                                                                                         Description
================ ================================================================================================================================= ======================================================================================================================================
``object_poses`` `visualization_msgs/MarkerArray <https://github.com/ros2/common_interfaces/blob/humble/visualization_msgs/msg/MarkerArray.msg>`__ A ``MarkerArray`` representing the poses of objects detected by the CenterPose network and interpreted by the CenterPose decoder node.
================ ================================================================================================================================= ======================================================================================================================================


.. |package_name| replace:: ``isaac_ros_centerpose``