Camera-based Perception with `Isaac Perceptor` on the `Nova Carter`
===================================================================

To run and evaluate camera-based 3D perception on the `Nova Carter`,
please follow the the suggested tutorials covering essential steps to launch `Isaac Perceptor`.
You can also integrate it with the navigation stack to enable autonomous navigation.

.. note::
    The `Nova Carter` has been unboxed and set up as expected by following
    :doc:`Getting Started </robots/nova_carter/getting_started>`.

Tutorials
------------------------------------------

.. _perceptor_openloop:

Running `Isaac Perceptor` on the `Nova Carter`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

See the :doc:`Tutorial: Running Camera-based 3D Perception with Isaac Perceptor</reference_workflows/isaac_perceptor/tutorials_on_carter/demo_perceptor>`
on how to launch the application, how to visualize, and evaluate the results.

Running `Isaac Perceptor` on Recorded Data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

See the :doc:`Tutorial: Recording and Playing Back Data for Isaac Perceptor </reference_workflows/isaac_perceptor/tutorials_on_devkit/tutorial_recording_and_playback>` on how to
record data on the `Nova Carter`, and how to run `Isaac Perceptor` on recordings.

Running `Isaac Perceptor` with the Navigation Stack on the `Nova Carter`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

After you complete :ref:`perceptor_openloop`,
you can see the :doc:`Tutorial: Autonomous Navigation with Isaac Perceptor and Nav2 </reference_workflows/isaac_perceptor/tutorials_on_carter/demo_navigation>`
on how to integrate  `Isaac Perceptor` with ROS2 Nav2 navigation stack and enable autonomous navigation.