===========
Visual SLAM
===========

Visual SLAM (simultaneous localization and mapping) solves the problem of knowing where the robot is
relative to some fixed pose. Robots can tell where they are relative to where they started through
use of odometry such as kinematic odometry (e.g. ticks from wheel encoders), visual odometry
(e.g. tracking visual features as you move relative to them), or inertial odometry (e.g. integrating
IMU readings. Odometry inevitably begins to drift, however, because small errors when estimating
motion between any two moments accumulate.

By building a graph of landmarks (distinct identifiable visual features on a map) from one or
multiple cameras, Visual SLAM can recognize when it has visited the same location again (closing the
loop). This allows for an accurate localization to correct for any accumulating drift.

.. toctree::
   :glob:

   **/index
