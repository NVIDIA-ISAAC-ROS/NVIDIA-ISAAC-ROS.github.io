============
Manipulation
============

Overview
--------

In robotics, the term "manipulator" has traditionally had a very broad definition, referring not only
to robots used for repositioning or modifying physical objects but also to robot arms generally, even
when used in non-contact applications such as automated optical inspection.  Increasingly, robotic
manipulators are being used for tasks where their motion must adapt to changing conditions as
perceived via cameras or other sensors.

An example of perception-driven manipulation is unstructured picking, where the robot might be tasked
with picking a variety of objects whose positions are not known in advance.  This requires modules
to detect a given object, determine its pose, compute a suitable grasp (dependent on the installed gripper),
plan a trajectory to bring the gripper to the desired pose while avoiding collisions, execute the planned
trajectory, grasp the object, and finally plan a trajectory to the desired place point, all in real time.
More challenging scenarios might require the planner to adapt to a changing environment where the presence
and positions of obstacles also vary.

Isaac for Manipulation consists of a set of components and
:doc:`reference workflows </reference_workflows/isaac_for_manipulation/index>` for advanced perception-driven
manipulation.  These components include state-of-the-art packages for
:doc:`object detection </repositories_and_packages/isaac_ros_object_detection/index>` and
:doc:`object pose estimation </repositories_and_packages/isaac_ros_pose_estimation/index>`, as well as
obstacle-aware motion generation, described in more detail below.


.. _concept-cumotion:

NVIDIA cuMotion
---------------

`NVIDIA cuMotion` is a software package for computing optimal-time, minimal-jerk trajectories for serial robot arms.
It is capable of avoiding collisions with obstacles represented as a set of cuboids, meshes, signed distance fields
(computed from one or more depth image streams using :doc:`nvblox </repositories_and_packages/isaac_ros_nvblox/index>`),
or any combination of the three.  cuMotion leverages NVIDIA hardware acceleration to compute such trajectories in
a fraction of a second on Jetson Thor or tens of milliseconds on a discrete GPU such as RTX 6000 (Ada Generation).

The planning capabilities of cuMotion are exposed through a plugin for
`MoveIt 2 <https://moveit.picknik.ai>`_.  In addition, a ROS 2 node is provided that uses the current joint
configuration of the robot to perform segmentation to filter out the robot from a depth image,
as needed to reconstruct obstacles in the environment without spurious contributions from the robot itself.

cuMotion incorporates technology developed by `NVIDIA Research <https://www.nvidia.com/en-us/research/>`_ and
leverages the `cuRobo library <https://curobo.org>`_ internally.

Refer to :doc:`Isaac ROS cuMotion </repositories_and_packages/isaac_ros_cumotion/index>` for more on cuMotion
and instructions for getting started.

Manipulation Orchestration
--------------------------

Isaac for Manipulation uses behavior trees to orchestrate complex manipulation workflows. This framework allows you to build robust, modular manipulation systems by combining pre-built behavior components that handle perception, motion planning, and gripper control. The behavior tree approach provides built-in error handling, retry mechanisms, and the ability to run multiple operations in parallel.

Refer to :doc:`Manipulation Orchestration </concepts/manipulation/orchestration>` for detailed information
about the behavior tree framework and :doc:`isaac_manipulator_orchestration </reference_workflows/isaac_for_manipulation/packages/isaac_manipulator_orchestration/index>` package for the behaviors and implementation details.

.. toctree::
   :maxdepth: 1

   orchestration.rst
   pick_and_place.rst

Robot Configuration
-------------------

To generate motion or perform segmentation for a given robot, cuMotion requires two files:

1. A universal/unified robot description format (``URDF``) file, describing basic kinematics.
2. An extended robot description format (``XRDF``) file, supplementing the ``URDF`` file with collision geometry
   (as a set of collision spheres), a definition of the configuration space (c-space) used for planning,
   potential modifiers to the ``URDF`` file, and other such data.

Refer to the following specification for details on ``XRDF``:

.. toctree::

   xrdf.rst

For convenience, a visual
`Robot Description Editor <https://docs.isaacsim.omniverse.nvidia.com/4.5.0/manipulators/manipulators_robot_description_editor.html>`_
with ``XRDF`` support is available in Isaac Sim 4.0 and later.

.. warning::

   In the current release, ``isaac_ros_cumotion`` also accepts robot description files in a legacy
   `cuRobo format <https://curobo.org/tutorials/1_robot_configuration.html>`_,
   but this support will be discontinued in a future release.  Use ``XRDF`` instead.


Grasp Authoring
---------------

With the capability to identify specific objects in the world along with their poses, the process
of computing high quality grasps between a specific gripper and object can be taken offline.  An
``isaac_grasp`` file is a YAML file that follows a human-readable format for storing predefined
grasps.

Refer to the following specification for details on ``isaac_grasp`` files.

.. toctree::
   :maxdepth: 1

   isaac_grasp.rst

For convenience, Isaac Sim 4.2 and later includes a
`Grasp Editor <https://docs.isaacsim.omniverse.nvidia.com/4.5.0/robot_setup/grasp_editor.html>`__
that supports hand authoring grasps and exporting them to an ``isaac_grasp`` file.  Additionally, it supports importing
an ``isaac_grasp`` file for the purpose of visualizing and validating the included grasps.


Pick and Place
--------------

Isaac for Manipulation includes a multi-object Pick and Place workflow that demonstrates perception-driven manipulation capabilities. This reference implementation showcases the integration of multiple Isaac ROS packages working together through the :doc:`manipulation orchestration </concepts/manipulation/orchestration>` framework.

The workflow supports both single-bin collection and multi-bin class-based sorting scenarios, with configurable parameters for different operational modes. It leverages behavior trees for robust coordination between perception and motion systems, enabling parallel object detection while executing sequential manipulation tasks.

For detailed workflow architecture and implementation, refer to :doc:`Multi-Object Pick and Place </concepts/manipulation/pick_and_place>` section. For hands-on experience, refer to the :doc:`tutorial </reference_workflows/isaac_for_manipulation/tutorials/tutorial_pick_and_place>`.


Tutorials
---------

To continue your exploration, review the following suggested tutorials:

.. toctree::
   :maxdepth: 1

   /concepts/manipulation/cumotion_moveit/tutorial_custom_manipulator
   /concepts/manipulation/cumotion_moveit/tutorial_isaac_sim

More advanced tutorials accompany the Isaac for Manipulation reference workflows:

* :doc:`Tutorial for obstacle avoidance and object following using cuMotion with perception </reference_workflows/isaac_for_manipulation/tutorials/tutorial_e2e>`
* :doc:`Tutorial for pick and place using cuMotion with perception </reference_workflows/isaac_for_manipulation/tutorials/tutorial_pick_and_place>`
* :doc:`Tutorial for deploying policies trained in Isaac Lab </reference_workflows/isaac_for_manipulation/tutorials/tutorial_sim_to_real>`
* :doc:`Tutorial for Isaac for Manipulation reference workflows with Isaac Sim </reference_workflows/isaac_for_manipulation/tutorials/tutorial_isaac_sim>`
